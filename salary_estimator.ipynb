{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiorgosNik/dev-salary-estimator/blob/main/salary_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K12Bkun-T0Z"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSFaceekf-a6"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q PyDrive\n",
        "%pip install -U -q geocoder\n",
        "%pip install -U -q tqdm\n",
        "%pip install -U -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apXdmT4L8GOD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from geopy.geocoders import Nominatim\n",
        "from tqdm import tqdm\n",
        "from tensorflow import feature_column\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6lmA34W-XqH"
      },
      "source": [
        "# Import and Format Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bb3MZdj5kHiy"
      },
      "source": [
        "## Data Import from GitHub repo\n",
        "The retrieved .csv file is stored in a pandas df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_B51PCL9fiR"
      },
      "outputs": [],
      "source": [
        "# Retrieve the dataset csv from GitHub\n",
        "csv_url = \"https://raw.githubusercontent.com/GiorgosNik/dev-salary-estimator/main/salary_data_2022.csv\"\n",
        "file_path = tf.keras.utils.get_file(\"salary_report\", csv_url)\n",
        "df = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4PV5g-79-AY"
      },
      "outputs": [],
      "source": [
        "df.columns = [\n",
        "    \"timestamp\",\n",
        "    \"devtype\",\n",
        "    \"languages\",\n",
        "    \"years_experience\",\n",
        "    \"personal_projects\",\n",
        "    \"sex\",\n",
        "    \"remote\",\n",
        "    \"city_residence\",\n",
        "    \"city_work\",\n",
        "    \"company_size\",\n",
        "    \"supervisor\",\n",
        "    \"education\",\n",
        "    \"relevant\",\n",
        "    \"salary\",\n",
        "]\n",
        "\n",
        "# Remove the timestamp as it is not relevant\n",
        "df = df.drop(columns=[\"timestamp\"])\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "dataset_size = len(df)\n",
        "print(\"The dataset contains {} salary entries\".format(dataset_size))\n",
        "df.head(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BasxDZwQmEhS"
      },
      "source": [
        "## Remove entries that contain very rare developer types or languages\n",
        "Entries that occur under 5 times are considered rare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Oqupvawe4Mo"
      },
      "outputs": [],
      "source": [
        "UNK = \"unk\"\n",
        "\n",
        "\n",
        "def categorize_clean_columns(df, col_name, threshold):\n",
        "    df[col_name] = df[col_name].map(lambda x: x.replace(\" \", \"\").split(\",\"))\n",
        "    c = Counter([item for sublist in df[col_name].values for item in sublist])\n",
        "\n",
        "    map_to_unk = set([el for el in c.elements() if c[el] <= threshold])\n",
        "\n",
        "    def map_devtype_unk(arr):\n",
        "        def x_or_unk(x):\n",
        "            if x in map_to_unk:\n",
        "                return UNK\n",
        "            return x\n",
        "\n",
        "        return [x_or_unk(x) for x in arr]\n",
        "\n",
        "    df[col_name] = df[col_name].map(lambda x: map_devtype_unk(x))\n",
        "\n",
        "    def is_sole_unknown(arr):\n",
        "        return arr[0] == UNK and len(arr) == 1\n",
        "\n",
        "    return df[df[col_name].map(is_sole_unknown) == False]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV5PbxCy1TfA"
      },
      "outputs": [],
      "source": [
        "def fix_devtype(dev_types):\n",
        "    return list(filter(lambda value: value != UNK, dev_types))\n",
        "\n",
        "\n",
        "def fix_languages(languages):\n",
        "    for i in range(len(languages)):\n",
        "        if languages[i] == \"Typescript\":\n",
        "            languages[i] = \"TypeScript\"\n",
        "        languages[i] = languages[i].strip()\n",
        "    return list(filter(lambda value: value != UNK, languages))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g-DYWIni0y2"
      },
      "outputs": [],
      "source": [
        "df = categorize_clean_columns(df, \"devtype\", 5)\n",
        "df = categorize_clean_columns(df, \"languages\", 5)\n",
        "\n",
        "df[\"languages\"] = df[\"languages\"].map(lambda x: fix_languages(x))\n",
        "df[\"devtype\"] = df[\"devtype\"].map(lambda x: fix_devtype(x))\n",
        "\n",
        "df = df[df[\"languages\"].map(lambda d: len(d)) > 0]\n",
        "df[df[\"devtype\"].map(lambda d: len(d)) > 0]\n",
        "\n",
        "print(\"After removing rare entries, the dataset contains {} entries.\".format(len(df)))\n",
        "print(\"This is {} less than the initial dataset.\".format(dataset_size - len(df)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw5o6JNzw4tt"
      },
      "source": [
        "## Fix Salary\n",
        "Normalize the salary input. Remove €/$ signs, commas and period signs.\n",
        "For values under 4000, consider the user gave a montly salary by mistake, and calculate the yearly salary by multiplying by 14 salaries.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE5kbqqzmhLC"
      },
      "outputs": [],
      "source": [
        "def fix_salary(salary):\n",
        "    salary = salary.replace(\".\", \"\")\n",
        "    salary = salary.replace(\",\", \"\")\n",
        "    salary = salary.replace(\"€\", \"\")\n",
        "    salary = salary.replace(\"$\", \"\")\n",
        "    salary = int(salary)\n",
        "    if salary < 4000:\n",
        "        salary = salary * 14\n",
        "\n",
        "    return salary\n",
        "\n",
        "\n",
        "df[\"salary\"] = df[\"salary\"].map(lambda x: fix_salary(str(int(x)))).astype(\"int32\")\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddsh8w5_yh7k"
      },
      "source": [
        "## Consider only results from Greece\n",
        "Using geopy, use the given city names to obtain the country of each response.\n",
        "Reject all values not relevant to Greece due to low sample size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUCaylBYotjf"
      },
      "outputs": [],
      "source": [
        "cities_residence, cities_work = pd.unique(df[\"city_residence\"].values), pd.unique(df[\"city_work\"].values)\n",
        "\n",
        "geo_locator = Nominatim(user_agent=\"test\")\n",
        "\n",
        "with tqdm(total=len(cities_residence), desc=\"Formatting City Names\") as city_progressbar:\n",
        "    for city in cities_residence:\n",
        "        try:\n",
        "            country = geo_locator.geocode(city).address.split(\",\")[-1].strip()\n",
        "            df[\"city_residence\"] = df[\"city_residence\"].replace(city, country)\n",
        "\n",
        "        except AttributeError:\n",
        "            df[\"city_residence\"] = df[\"city_residence\"].replace(city, \"UNK\")\n",
        "        city_progressbar.update(1)\n",
        "\n",
        "df = df[df.city_residence == \"Ελλάς\"]\n",
        "\n",
        "df = df.drop(columns=[\"city_residence\", \"city_work\"])\n",
        "df.head(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqSrT3zzPQl"
      },
      "source": [
        "## Replace NA values\n",
        "Replace NA values regarding relevant projects with \"No\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tTAeQUGeE5X"
      },
      "outputs": [],
      "source": [
        "df[\"relevant\"] = df[\"relevant\"].fillna(\"Όχι\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0-1Sgxzei4"
      },
      "source": [
        "# Define Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMfzC-xtfj7I"
      },
      "outputs": [],
      "source": [
        "category_columns = [\n",
        "    \"company_size\",\n",
        "    \"remote\",\n",
        "    \"supervisor\",\n",
        "    \"personal_projects\",\n",
        "    \"sex\",\n",
        "    \"education\",\n",
        "    \"relevant\",\n",
        "]\n",
        "\n",
        "for col in category_columns:\n",
        "    df[f\"{col}_xf\"] = df[col].astype(\"category\")\n",
        "\n",
        "df = df.drop(columns=category_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e7GFD_hgY89"
      },
      "outputs": [],
      "source": [
        "multi_category_columns = [\"devtype\", \"languages\"]\n",
        "\n",
        "\n",
        "def col_title(col, word):\n",
        "    return f\"{col}_{word}\"\n",
        "\n",
        "\n",
        "for col in multi_category_columns:\n",
        "    vocab = set([item for sublist in df[col].values for item in sublist])\n",
        "    for word in vocab:\n",
        "        df[col_title(col, word)] = 0\n",
        "        df[col_title(col, word)] = df[col_title(col, word)].astype(\"int32\")\n",
        "    print(vocab)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    for col in multi_category_columns:\n",
        "        words = row[col]\n",
        "        for word in words:\n",
        "            df.loc[index, col_title(col, word)] = 1\n",
        "\n",
        "bad_tf_scope_names = [(\"languages_C#\", \"languages_Csharp\"), (\"languages_C++\", \"languages_Cpp\")]\n",
        "for before, after in bad_tf_scope_names:\n",
        "    df[after] = df[before]\n",
        "    df = df.drop(columns=[before])\n",
        "\n",
        "df = df.drop(columns=multi_category_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEhwFrJ52J-O"
      },
      "source": [
        "## Split the dataset into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL8C644Pgs2X"
      },
      "outputs": [],
      "source": [
        "train, val = train_test_split(df, test_size=0.2)\n",
        "print(len(train), \"train examples\")\n",
        "print(len(val), \"validation examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbjuD0nGg2lz"
      },
      "outputs": [],
      "source": [
        "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
        "    df = df.copy()\n",
        "    labels = df.pop(\"salary\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(df))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = df_to_dataset(train, batch_size=32)\n",
        "eval_ds = df_to_dataset(train, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky-qm-mwg9Vg"
      },
      "outputs": [],
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "    feature_column_keys = list(feature_batch.keys())\n",
        "    print(\"Every feature:\", feature_column_keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD49BSqe2VVo"
      },
      "source": [
        "## Encode features into columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTKmYnRuhALW"
      },
      "outputs": [],
      "source": [
        "feature_columns = []\n",
        "\n",
        "numeric_features = [\n",
        "    x for x in feature_column_keys if (\"devtype_\" in x or \"languages_\" in x or \"years_experience\" in x)\n",
        "]\n",
        "categorical_features = [x for x in feature_column_keys if \"_xf\" in x]\n",
        "\n",
        "for feature in numeric_features:\n",
        "    feature_columns.append(feature_column.numeric_column(feature))\n",
        "\n",
        "for feature in categorical_features:\n",
        "    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
        "        feature, pd.unique(df[feature].values)\n",
        "    )\n",
        "\n",
        "    feature_columns.append(feature_column.indicator_column(categorical_column))\n",
        "\n",
        "print(feature_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClxgUGOR2eE9"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcKwFaXjhB8M"
      },
      "outputs": [],
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model = tf.keras.Sequential([feature_layer, layers.Dense(8, activation=\"relu\"), layers.Dense(1)])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9), loss=\"mae\", metrics=[\"mae\"])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=\"model.{epoch:02d}-{val_loss:.2f}.h5\"),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=\"./logs\"),\n",
        "]\n",
        "print(train_ds)\n",
        "model.fit(train_ds, validation_data=eval_ds, epochs=20, callbacks=callbacks)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the Model\n",
        "Save the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('./model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83SIIyqL2gzs"
      },
      "source": [
        "# Try your values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOCTrzYphmL8"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('./model')\n",
        "\n",
        "input = {\n",
        "    'years_experience': 0.5,\n",
        "    'company_size_xf': '11-50',\n",
        "    'education_xf': \"Bachelor's\",\n",
        "    'relevant_xf': \"Ναι\",\n",
        "    'personal_projects_xf': 'Ναι',\n",
        "    'remote_xf': 'Και τα δύο',\n",
        "    'supervisor_xf': 'Ναι',\n",
        "    'sex_xf': 'Άντρας',\n",
        "    'devtype_Backend': 1 ,              \n",
        "    'devtype_Desktopapps': 0,         \n",
        "    'devtype_DevOps': 0,            \n",
        "    'devtype_AI/ML': 0 ,       \n",
        "    'devtype_BI': 0 ,\n",
        "    'devtype_Cybersecurity': 0,\n",
        "    'devtype_Embedded': 0,\n",
        "    'devtype_Gaming': 0,                     \n",
        "    'devtype_Frontend': 1,        \n",
        "    'devtype_Mobileapps': 0,           \n",
        "    'languages_C': 0 ,\n",
        "    'languages_SQL': 0,              \n",
        "    'languages_PHP': 0 ,             \n",
        "    'languages_JavaScript': 1 ,         \n",
        "    'languages_Kotlin' : 0 ,\n",
        "    'languages_TypeScript' : 0,              \n",
        "    'languages_Python': 1 ,            \n",
        "    'languages_Ruby': 0 ,               \n",
        "    'languages_Bash': 0,             \n",
        "    'languages_Go': 0 ,             \n",
        "    'languages_Java': 0 ,            \n",
        "    'languages_Swift': 0 ,            \n",
        "    'languages_Csharp': 0 ,         \n",
        "    'languages_Cpp': 0 , \n",
        "}\n",
        "\n",
        "input = {k: [v] for k, v in input.items()}\n",
        "\n",
        "prediction = model(input).numpy()[0][0]\n",
        "f'Βγάζεις: {prediction} ευρώ το χρόνο'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMQMuEgU0LiwxVj0etuaxr4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
